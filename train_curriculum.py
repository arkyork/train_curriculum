from DQNAgent import DQNAgent
from LineWorld import LineWorld
from utils import plot_results
def train_curriculum():
    stages = [5, 10, 20, 50]  # ç°¡å˜â†’é›£ã—ã„
    agent = DQNAgent()
    episodes_per_stage = 1000
    
    # ğŸ”¹ ã‚°ãƒ©ãƒ•ç”¨ã«è¨˜éŒ²
    stage_rewards = []  # å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®å¹³å‡å ±é…¬
    all_rewards = []    # å…¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®æ¨ç§»
    
    for length in stages:
        env = LineWorld(length)
        rewards = []

        print(f"\n=== ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ  Stage: ã‚´ãƒ¼ãƒ«è·é›¢ = {length} ===")


        for epi in range(episodes_per_stage):
            state = env.reset()
            done = False
            total_reward = 0
            eps = max(0.1, 0.9 - epi * 0.001)  # Îµ-greedyæ¸›è¡°

            while not done:
                action = agent.actions(state, eps)
                next_state, reward, done = env.step(action)
                agent.store(state, action, reward, next_state, done)
                agent.one_step()
                state = next_state
                total_reward += reward

            rewards.append(total_reward)
            all_rewards.append(total_reward)

            if (epi + 1) % 50 == 0:
                avg_reward = sum(rewards[-50:]) / 50
                print(f"Episode {epi+1}: total_reward = {total_reward:.2f}, avg(last50)={avg_reward:.2f}")
        # ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆæ›´æ–°
        agent.update_target()
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸å¹³å‡ã‚’è¨˜éŒ²
        avg_stage_reward = sum(rewards) / len(rewards)
        stage_rewards.append(avg_stage_reward)
    
    # ã‚°ãƒ©ãƒ•æç”»
    plot_results(all_rewards, stage_rewards, stages, episodes_per_stage)

if __name__ == "__main__":
    train_curriculum()
